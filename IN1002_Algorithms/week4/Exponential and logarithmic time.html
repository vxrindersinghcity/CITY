<!DOCTYPE html>
<!-- saved from url=(0088)https://moodle4.city.ac.uk/pluginfile.php/885218/mod_resource/content/6/notes/index.html -->
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script id="f5_cspm">(function(){var f5_cspm={f5_p:'PJAEFNDIDLBJKDIJPGDMKBABCJPFJAAAFCGCPHKHLGDNLBLNFMJPGAMOJAIOKBGHOLLBJHHNAABKPNDFGJNALEBFAAHEPIFEPLNGIAOLFPIAADLCIMLFFJBABIPMKGIP',setCharAt:function(str,index,chr){if(index>str.length-1)return str;return str.substr(0,index)+chr+str.substr(index+1);},get_byte:function(str,i){var s=(i/16)|0;i=(i&15);s=s*32;return((str.charCodeAt(i+16+s)-65)<<4)|(str.charCodeAt(i+s)-65);},set_byte:function(str,i,b){var s=(i/16)|0;i=(i&15);s=s*32;str=f5_cspm.setCharAt(str,(i+16+s),String.fromCharCode((b>>4)+65));str=f5_cspm.setCharAt(str,(i+s),String.fromCharCode((b&15)+65));return str;},set_latency:function(str,latency){latency=latency&0xffff;str=f5_cspm.set_byte(str,40,(latency>>8));str=f5_cspm.set_byte(str,41,(latency&0xff));str=f5_cspm.set_byte(str,35,2);return str;},wait_perf_data:function(){try{var wp=window.performance.timing;if(wp.loadEventEnd>0){var res=wp.loadEventEnd-wp.navigationStart;if(res<60001){var cookie_val=f5_cspm.set_latency(f5_cspm.f5_p,res);window.document.cookie='f5avr0139236398aaaaaaaaaaaaaaaa_cspm_='+encodeURIComponent(cookie_val)+';path=/;'+'';}
return;}}
catch(err){return;}
setTimeout(f5_cspm.wait_perf_data,100);return;},go:function(){var chunk=window.document.cookie.split(/\s*;\s*/);for(var i=0;i<chunk.length;++i){var pair=chunk[i].split(/\s*=\s*/);if(pair[0]=='f5_cspm'&&pair[1]=='1234')
{var d=new Date();d.setTime(d.getTime()-1000);window.document.cookie='f5_cspm=;expires='+d.toUTCString()+';path=/;'+';';setTimeout(f5_cspm.wait_perf_data,100);}}}}
f5_cspm.go();}());</script>

<link rel="stylesheet" type="text/css" href="./Exponential and logarithmic time_files/moodle-custom-styles.css">
<link rel="stylesheet" type="text/css" href="./Exponential and logarithmic time_files/kube.min.css">
<link rel="stylesheet" type="text/css" href="./Exponential and logarithmic time_files/master.css">
<link rel="stylesheet" type="text/css" href="./Exponential and logarithmic time_files/algorithms.css">
<link href="./Exponential and logarithmic time_files/css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="./Exponential and logarithmic time_files/applet.js.download"></script>
<script type="text/javascript" src="./Exponential and logarithmic time_files/codeapplet.js.download"></script>

<title>Exponential and logarithmic time</title>
</head>

<body style="font-size: 100%; ">
<div id="page">
<div class="soiContent">

<h1>Exponential and logarithmic time</h1>

<div class="units-row">
<div class="unit-60">

<p>
So far we've considered only complexity functions O(1), O(n), O(n<sup>2</sup>)
or O(n<sup>3</sup>), in general O(n<sup>k</sup>) for some whole number k.
This week we'll consider other functions that characterize common algorithms,
in particular,
</p><dl>
<dt>exponential time</dt><dd>(very bad),
typically found in algorithms that perform an exhaustive search.
</dd><dt>logarithmic time</dt><dd>(very good),
typically achieved by algorithms that cut the size of the problem at each step.
</dd></dl>
<p>
An important example of the latter class is
the <strong>binary search</strong> algorithm.

</p><p>
We'll also need to consider a more general definition of big-O notation to
accommodate these functions, and others.

</p></div>
</div>

<h2>Exponential time</h2>

<div class="units-row">
<div class="unit-60">

<p>
Many algorithms operate by considering all possibilities in a set,
a strategy called <strong>exhaustive search</strong>.
This is often very expensive.

</p><h3>Satisfiability checking</h3>

<p>The <strong>satisfiability checking</strong> problem is to determine
whether, given a formula, there is an assignment of truth values
to the variables that makes it true.
For example, consider the following:
</p><ul>
<li> p ∧ ¬p
</li><li> (p ∨ q) ∧ ¬p
</li><li> ¬p ∧ ((¬q ∨ r) → p)
</li><li> and so on
</li></ul>

<p>
One method for determining whether or not a formula is satisfiable
is using truth tables, following directly from the definition.
For formula f, containing variables x1, ..., xn,
</p><ul>
<li>Generate all rows of the truth table for f.
</li><li>If any row gives true, then f is satisfiable, else f is not satisfiable.
</li></ul>

<p>The input to the algorithm is the formula f.
An appropriate measure of size is the number of distinct variables in f.
</p><p>The main step is the generation of a row of the truth table.
</p><ul>
<li>If there is only one variable, we must test 2 rows.
</li><li>If there are two variables, we must test 2*2 = 4 rows.
</li><li>If there are three variables, we must test 2*2*2 = 8 rows.
</li><li>If there are four variables, we must test 2*2*2*2 = 16 rows.
</li></ul>

<p>
For n variables, 2*2*2*...*2 = 2<sup>n</sup> rows.

</p></div>

<div class="unit-40">

<h4>One variable: 2 rows</h4>

<center>
<table>
<tbody><tr>
<th>p</th> <th>p ∧ ¬p</th>
</tr>
<tr>
<td style="background: #fdb">0</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">1</td>
<td>0</td>
</tr>
</tbody></table>
</center>

<h4>Two variables: 4 rows</h4>

<center>
<table>
<tbody><tr>
<th>p</th> <th>q</th> <th>(p ∨ q) ∧ ¬p</th>
</tr>
<tr>
<td style="background: #fdb">0</td>
<td style="background: #fdb">0</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">0</td>
<td style="background: #fdb">1</td>
<td>1</td>
</tr>
<tr>
<td style="background: #fdb">1</td>
<td style="background: #fdb">0</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">1</td>
<td style="background: #fdb">1</td>
<td>0</td>
</tr>
</tbody></table>
</center>

<h4>Three variables: 8 rows</h4>

<center>
<table>
<tbody><tr>
<th>p</th> <th>q</th> <th>r</th> <th>¬p ∧ ((¬q ∨ r) → p)</th>
</tr>
<tr>
<td style="background: #fdb">0</td>
<td style="background: #fdb">0</td>
<td style="background: #fdb">0</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">0</td>
<td style="background: #fdb">0</td>
<td style="background: #fdb">1</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">0</td>
<td style="background: #fdb">1</td>
<td style="background: #fdb">0</td>
<td>1</td>
</tr>
<tr>
<td style="background: #fdb">0</td>
<td style="background: #fdb">1</td>
<td style="background: #fdb">1</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">1</td>
<td style="background: #fdb">0</td>
<td style="background: #fdb">0</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">1</td>
<td style="background: #fdb">0</td>
<td style="background: #fdb">1</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">1</td>
<td style="background: #fdb">1</td>
<td style="background: #fdb">0</td>
<td>0</td>
</tr>
<tr>
<td style="background: #fdb">1</td>
<td style="background: #fdb">1</td>
<td style="background: #fdb">1</td>
<td>0</td>
</tr>
</tbody></table>
</center>
</div>
</div>

<div class="units-row">
<div class="unit-60">

<h4>Subset Sum algorithm</h4>

<p>The straightforward algorithm for the subset sum problem
(a special case of the knapsack problem) is similar:
try each selection and choose the largest one that fits.
The example at right is has weights 23, 39, 57 and capacity 100.

</p><p>
For 3 items, the number of selections to check is 2*2*2 = 2<sup>3</sup> = 8.

</p><p>In general, for n items
the number of selections to check is 2*2*2*...*2 = 2<sup>n</sup>.

</p><div class="aside">
As we'll see in week 8, the best known algorithms for these problems
aren't significantly faster than exhaustive search.
</div>

</div>

<div class="unit-40">
<center>
<table>
<tbody><tr>
<th>Selection</th>
<th>Sum</th>
</tr>
<tr><td>
<span style="color: #aaa">23</span> +
<span style="color: #aaa">39</span> +
<span style="color: #aaa">57</span>
</td><td style="font-weight: bold; color: #7c7">0</td></tr>
<tr><td>
<span style="color: #aaa">23</span> +
<span style="color: #aaa">39</span> +
57
</td><td style="font-weight: bold; color: #7c7">57</td></tr>
<tr><td>
<span style="color: #aaa">23</span> +
39 +
<span style="color: #aaa">57</span>
</td><td style="font-weight: bold; color: #7c7">39</td></tr>
<tr><td>
<span style="color: #aaa">23</span> +
39 +
57
</td><td style="font-weight: bold; color: #7c7">96</td><td>(best)</td></tr>
<tr><td>
23 +
<span style="color: #aaa">39</span> +
<span style="color: #aaa">57</span>
</td><td style="font-weight: bold; color: #7c7">23</td></tr>
<tr><td>
23 +
<span style="color: #aaa">39</span> +
57
</td><td style="font-weight: bold; color: #7c7">80</td></tr>
<tr><td>
23 +
39 +
<span style="color: #aaa">57</span>
</td><td style="font-weight: bold; color: #7c7">62</td></tr>
<tr><td>
23 +
39 +
57
</td><td style="font-weight: bold; color: #c77">119</td><td>(too big)
</td></tr></tbody></table>
</center>
</div>
</div>

<h4>Powers of two</h4>

<div class="units-row">
<div class="unit-60">

<p>
The cost functions of the satisfiability tester and the straightforward
knapsack algorithm are powers of two, which increase very steeply:

</p><table>
<tbody><tr>
<td>2<sup>1</sup> = 2</td><td>= 2</td>
<td></td>
<td>2<sup>6</sup> = 2*2*2*2*2*2</td><td>= 64</td>
</tr>
<tr>
<td>2<sup>2</sup> = 2*2</td><td>= 4</td>
<td></td>
<td>2<sup>7</sup> = 2*2*2*2*2*2*2</td><td>= 128</td>
</tr>
<tr>
<td>2<sup>3</sup> = 2*2*2</td><td>= 8</td>
<td></td>
<td>2<sup>8</sup> = 2*2*2*2*2*2*2*2</td><td>= 256</td>
</tr>
<tr>
<td>2<sup>4</sup> = 2*2*2*2</td><td>= 16</td>
<td></td>
<td>2<sup>9</sup> = 2*2*2*2*2*2*2*2*2</td><td>= 512</td>
</tr>
<tr>
<td>2<sup>5</sup> = 2*2*2*2*2</td><td>= 32</td>
<td></td>
<td>2<sup>10</sup> = 2*2*2*2*2*2*2*2*2*2</td><td>= 1024</td>
</tr>
</tbody></table>

<div class="aside">
Every programmer should know the powers of 2.
The approximation 2<sup>10</sup> ≈ 1000 is also very useful.
</div>

<h3>Recall: properties of powers</h3>

<ul style="font-size: 150%">
<li>2<sup>a</sup> * 2<sup>b</sup> = 2<sup>a+b</sup>
</li><li>(2<sup>a</sup>)<sup>b</sup> = 2<sup>a*b</sup>
</li></ul>

<div class="task">
Give approximate values for 2<sup>16</sup>, 2<sup>30</sup> and 2<sup>32</sup>.
</div>

</div>

<div class="unit-40">
<img src="./Exponential and logarithmic time_files/powersoftwo.svg">
</div>
</div>

<div class="units-row">
<div class="unit-60">

<h2>Big-O notation revisited</h2>

<p>
In Week 2 we discussed big-O notation for polynomial functions,
yielding O(n), O(n<sup>2</sup>), O(n<sup>3</sup>), ..., O(n<sup>k</sup>)
for any positive whole number k.
Now that we're dealing with other cost functions, such as 2<sup>n</sup>,
we need a generalized definition.

</p><p>
Consider the function f(n) = 3 n<sup>3</sup> + 27 n<sup>2</sup> + 10 n + 52.
When we say that this is O(n<sup>3</sup>), we mean that it grows no faster
than n<sup>3</sup>.
To compare the rates of growth of these two functions,
we plot their ratio, f(n)/n<sup>3</sup>.

</p><p>
From the graph at right, we see that for large n,
the ratio between the two functions has an upper bound:
</p><center>
<table>
<tbody><tr><td>For n &gt; 2,</td><td>f(n)/n<sup>3</sup> ≤ 30</td>
<td>or equivalently f(n) ≤ 30 n<sup>3</sup></td></tr>
<tr><td>For n &gt; 4,</td><td>f(n)/n<sup>3</sup> ≤ 12</td>
<td>or equivalently f(n) ≤ 12 n<sup>3</sup></td></tr>
<tr><td>For n &gt; 10,</td><td>f(n)/n<sup>3</sup> ≤ 6</td>
<td>or equivalently f(n) ≤ 6 n<sup>3</sup></td></tr>
</tbody></table>
</center>
<p>
Many such bounds are possible; any of these will do.

</p><h3>Formal definition of big-O notation</h3>

<div class="definition">
A function <i>f(n)</i> belongs to the complexity class <i>O(g(n))</i> if
there is a size <i>N</i> and a constant <i>c</i> such that
<ul>
<li>for all n &gt; N, <i>f(n)</i> ≤ <i>c g(n)</i>
</li></ul>
</div>

The are two constants here, both of which can be as big as we like:
<dl>
<dt><i>N</i>
</dt><dd>which means only the behaviour for large <i>n</i> matters.
</dd><dt><i>c</i>
</dt><dd>which means that we ignore constant factors.
</dd></dl>

<p>
A consequence of this definition is that if a function is O(n<sup>2</sup>),
then it is also O(n<sup>3</sup>), O(n<sup>4</sup>), etc.

</p><p class="formula">
O(1) ⊂ O(n) ⊂ O(n<sup>2</sup>) ⊂ O(n<sup>3</sup>) ⊂ ... ⊂ O(n<sup><i>k</i></sup>) ⊂ ... ⊂ O(2<sup>n</sup>)

</p><p>
However we generally prefer the tightest class.

</p><div class="aside">
A function belongs to O(g(n)) if it grows no faster than g(n).
There is an associated notation, Θ(g(n)),
of functions that grow at the same rate as g(n).
(That's a capital Greek letter theta.)
</div>
</div>

<div class="unit-40">
<img src="./Exponential and logarithmic time_files/cubic-comp.svg">
<center>
<p class="annotation">Two cubic functions</p>
</center>
<img src="./Exponential and logarithmic time_files/cubic.svg">
<center>
<p>
Plot of (3 n<sup>3</sup> + 27 n<sup>2</sup> + 10 n + 52)/n<sup>3</sup>
</p></center>
<center>
<img src="./Exponential and logarithmic time_files/Paul_Bachmann.jpg" width="50%">
</center>
<p class="annotation">
Big-O notation predates computer science by several decades.
It was introduced by the German mathematician Paul Bachmann in 1894.

</p></div>
</div>

<div class="units-row">
<div class="unit-60">

<h3>Exponential growth</h3>

<p>
The graph at right compares the rate of growth of 2<sup>n</sup> with
that of n<sup>3</sup>, by plotting 2<sup>n</sup>/n<sup>3</sup>.

</p><ul>
<li>For small values of n, 2<sup>n</sup> ≤ n<sup>3</sup>.
</li><li>As n gets larger, the ratio between the two functions grows without limit.
</li></ul>

<p>
This means that the function 2<sup>n</sup> is not O(n<sup>3</sup>).
Indeed it is not O(n<sup>10</sup>) or O(n<sup>100</sup>) or
O(n<sup>k</sup>) for any whole number k.
It grows faster than any polynomial function.

</p><p>
This also means that any polynomial function (made up of constant powers of n),
like 3 n<sup>3</sup> + 27 n<sup>2</sup> + 10 n + 52, is also O(2<sup>n</sup>).
However, it is more informative to say it's O(n<sup>3</sup>).

</p></div>

<div class="unit-40">
<img src="./Exponential and logarithmic time_files/exponential.svg">
<center>
<p>
Plot of 2<sup>n</sup>/n<sup>3</sup>
</p></center>
</div>

</div>

<div class="units-row">
<div class="unit-60">

<h3>Operations on order functions</h3>

<p>
Order notation simplifies calculations considerably.
One common operation arises when an algorithm does one thing after another:
we want to add the costs of the two parts.

</p><p>
For example:
</p><dl>
<dt>Property</dt><dd>
If f<sub>1</sub>(n) and f<sub>2</sub>(n) are both O(g(n)),
then f<sub>1</sub>(n) + f<sub>2</sub>(n) is also O(g(n)).
</dd><dt>Proof</dt><dd>
From the definition, we know that there are constants N<sub>1</sub>,
N<sub>2</sub>, c<sub>1</sub> and c<sub>2</sub> such that
<ul>
<li>for all n &gt; N<sub>1</sub>, f<sub>1</sub>(n)/g(n) ≤ c<sub>1</sub>, and
</li><li>for all n &gt; N<sub>2</sub>, f<sub>2</sub>(n)/g(n) ≤ c<sub>2</sub>
</li></ul>
<p>
If N is the larger of N<sub>1</sub> and N<sub>2</sub>, then
</p><ul>
<li>for all n &gt; N, (f<sub>1</sub>(n) + f<sub>2</sub>(n))/g(n) ≤ c<sub>1</sub> + c<sub>2</sub>
</li></ul>
i.e. f<sub>1</sub>(n) + f<sub>2</sub>(n) is also O(g(n)).
</dd></dl>

<p>
For example,
</p><ul>
<li>4 n<sup>3</sup> + 6 n<sup>3</sup> is O(n<sup>3</sup>),
because both functions are O(n<sup>3</sup>).
</li><li>3 n<sup>20</sup> + 2<sup>n</sup> is O(2<sup>n</sup>),
because both functions are O(2<sup>n</sup>).
The faster-growing 2<sup>n</sup> dominates n<sup>20</sup>
</li></ul>

<p>
We can use this to work out the complexity of methods from their parts.
For example,
</p><ul>
<li>If a method performs an operation taking O(n<sup>2</sup>) time
followed by another operation taking O(n<sup>2</sup>) time,
the whole thing takes O(n<sup>2</sup>) time.
</li><li>
If a method performs an operation taking O(n<sup>3</sup>) time
followed by another operation taking O(2<sup>n</sup>) time,
the whole thing takes O(2<sup>n</sup>) time.
</li></ul>

</div>

<div class="unit-40">
<img src="./Exponential and logarithmic time_files/f1.svg">
<img src="./Exponential and logarithmic time_files/f2.svg">
<img src="./Exponential and logarithmic time_files/f3.svg">
</div>

</div>

<h2>Searching an array</h2>

<p>
Last week we considered searching for a key in an array using the
sequential search algorithm, which takes O(n) time.

</p><div class="hidden">
<div class="pseudocode" id="SequentialSearch">
<div class="codeheader">SequentialSearch(a[0..n-1], k)</div>
<pre>i ← 0
</pre>
<span class="invariant"><b>invariant:</b> 0 ≤ i ≤ n and k is not in a[0] ... a[i-1]</span>
<pre>WHILE i &lt; n AND a[i] ≠ k
        i ← i+1
RETURN i
</pre>
</div>
</div>

<script language="JavaScript">
getProcedure("SequentialSearch").cellColour = leftToRightColour("a", "i");
</script>

<div class="task">
Recall sequential search:

<canvas id="sequentialSearch" width="750" height="180">
Your browser does not support the HTML5 canvas tag.
</canvas>
<p>
<button onclick="sequentialSearch.reset()">Reset</button>
<button onclick="sequentialSearch.step()">Single step</button>
<button onclick="sequentialSearch.bigStep()">Big step</button>
<button onclick="sequentialSearch.run()">Run</button>
<button onclick="sequentialSearch.stop()">Stop</button>

<script language="JavaScript">
var sequentialSearch = new CodeApplet("sequentialSearch", "SequentialSearch",
        {a: [27, 14, 77, 53, 18, 85, 18, 94, 34], k: 94});
</script>

</p></div>

<br>

<h3>Binary search (logarithmic time)</h3>

<p>
If the array has been arranged in ascending order, we can do much better.
Let <code>mid</code> be an index in the middle of the array:

</p><center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>mid-1</td>
<td>mid</td>
<td>mid+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="cell" colspan="5" style="text-align:center"></td>
<td class="cell"></td>
<td class="cell" colspan="5" style="text-align:center"></td>
</tr>
</tbody></table>
</center>

<p>
If we compare a[mid] with k, there are three cases:
</p><ul>
<li>If a[mid] = k, then we are done.

</li><li>If a[mid] &lt; k, then we need only search a[mid+1..n-1]:

<center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>mid-1</td>
<td>mid</td>
<td>mid+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="6" style="text-align:center">&lt; k</td>
<td class="cell" colspan="5" style="text-align:center"></td>
</tr>
</tbody></table>
</center>

</li><li>If a[mid] &gt; k, then we need only search a[0..mid-1]:

<center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>mid-1</td>
<td>mid</td>
<td>mid+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="cell" colspan="5" style="text-align:center"></td>
<td class="sortedcell" colspan="6" style="text-align:center">&gt; k</td>
</tr>
</tbody></table>
</center>

</li></ul>

<p>
Repeating this process, we search smaller and smaller sub-arrays,
until either we find k or end up with an empty search space.
We need two variables <code>lo</code> and <code>hi</code> to keep track
of the search area:

</p><center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>lo-1</td>
<td>lo</td><td>...</td><td>mid-1</td><td>mid</td><td>mid+1</td><td>...</td><td>hi</td>
<td>hi+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="5" style="text-align:center">&lt; k</td>
<td class="cell" colspan="3"></td>
<td class="cell"></td>
<td class="cell" colspan="3"></td>
<td class="sortedcell" colspan="5" style="text-align:center">&gt; k</td>
</tr>
</tbody></table>
</center>

<p>
On each iteration, we compare k with a[mid]:
</p><ul>
<li>
If they are equal, we have found the entry we are looking for.

</li><li>
If a[mid] &lt; k, we can eliminate everything from mid down:

<center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>lo-1</td>
<td>lo</td><td>...</td><td>mid-1</td><td>mid</td><td>mid+1</td><td>...</td><td>hi</td>
<td>hi+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="9" style="text-align:center">&lt; k</td>
<td class="cell" colspan="3"></td>
<td class="sortedcell" colspan="5" style="text-align:center">&gt; k</td>
</tr>
</tbody></table>
</center>

</li><li>
If a[mid] &gt; k, we can eliminate everything from mid up:

<center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>lo-1</td>
<td>lo</td><td>...</td><td>mid-1</td><td>mid</td><td>mid+1</td><td>...</td><td>hi</td>
<td>hi+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="5" style="text-align:center">&lt; k</td>
<td class="cell" colspan="3"></td>
<td class="sortedcell" colspan="9" style="text-align:center">&gt; k</td>
</tr>
</tbody></table>
</center>

</li></ul>

<p>
If the key we're looking for isn't in the array,
<code>lo</code> and <code>hi</code> will eventually cross,
and we'll have this situation:

</p><center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>hi = lo-1</td>
<td>lo = hi+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="5" style="text-align:center">&lt; k</td>
<td class="sortedcell" colspan="5" style="text-align:center">&gt; k</td>
</tr>
</tbody></table>
</center>

<p>
Thus we have the following algorithm:

</p><div class="pseudocode" id="BinarySearch">
<div class="codeheader">BinarySearch(a[0..n-1], k)</div>
<pre>lo ← 0
hi ← n-1
</pre>
<span class="invariant"><b>invariant:</b> 0 ≤ lo ≤ hi+1 ≤ n and a[0..lo-1] &lt; k &lt; a[hi+1..n-1]</span>
<pre>WHILE lo ≤ hi
        mid ← (lo+hi) DIV 2
        IF a[mid] = k
                RETURN mid
        IF a[mid] &lt; k
                lo ← mid+1
        ELSE
                hi ← mid-1
RETURN -1
</pre>
</div>

<script language="JavaScript">
function bsearchColour(state, aname, ix) {
	if (aname == 'a') {
		if (state.lo !== '' && ix < Number(state.lo) ||
		    state.hi !== '' && ix > Number(state.hi))
			return ColourScheme.done;
		if (state.mid !== '' && ix == Number(state.mid))
			return ColourScheme.highlight;
	}
        return ColourScheme.plain;
};

getProcedure("BinarySearch").cellColour = bsearchColour;
</script>

<div class="task">
Try stepping through binary search:

<canvas id="binarySearch" width="950" height="290">
Your browser does not support the HTML5 canvas tag.
</canvas>
Search key:
<input type="text" id="binarySearchKey" size="2" value="62" onchange="binarySearch.setVar(&#39;k&#39;, Number(this.value))">
<button onclick="binarySearch.reset()">Reset</button>
<button onclick="binarySearch.step()">Single step</button>
<button onclick="binarySearch.bigStep()">Big step</button>
<button onclick="binarySearch.run()">Run</button>
<button onclick="binarySearch.stop()">Stop</button>

<script language="JavaScript">
var binarySearch = new CodeApplet("binarySearch", "BinarySearch",
	{a:[14,16,22,27,34,36,40,47,51,58,62,63,77,85,93],
	 k:Number(document.getElementById('binarySearchKey').value)});
</script>

</div>

<h3>Example</h3>

<p>
Consider searching for 62 in this array:

</p><center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td>1</td><td>2</td><td>3</td><td>4</td>
<td>5</td><td>6</td><td>7</td><td>8</td><td>9</td>
<td>10</td><td>11</td><td>12</td>
<td>13</td><td>14</td>
</tr><tr>
<td>a</td>
<td class="cell">14</td>
<td class="cell">16</td>
<td class="cell">22</td>
<td class="cell">27</td>
<td class="cell">34</td>
<td class="cell">36</td>
<td class="cell">40</td>
<td class="cell">47</td>
<td class="cell">51</td>
<td class="cell">58</td>
<td class="cell">62</td>
<td class="cell">63</td>
<td class="cell">77</td>
<td class="cell">85</td>
<td class="cell">93</td>
</tr>
</tbody></table>
</center>

<p>
Stepping through the values of the variables <code>lo</code> and
<code>hi</code> on each iteration:

</p><table>
<tbody><tr>
<th></th>
<th>lo</th>
<th>hi</th>
<th></th>
</tr>
<tr>
<td>Before entering the loop</td>
<td>0</td>
<td>14</td>
<td>mid = 7, examine a[7] = 47</td>
</tr><tr>
<td>After the first iteration</td>
<td>8</td>
<td>14</td>
<td>mid = 11, examine a[11] = 63</td>
</tr><tr>
<td>After the second iteration</td>
<td>8</td>
<td>10</td>
<td>mid = 9, examine a[9] = 58</td>
</tr><tr>
<td>After the third iteration</td>
<td>10</td>
<td>10</td>
<td>mid = 10, examine a[10] = 62, target found</td>
</tr>
</tbody></table>

<p>
So we found the key after examining 4 elements of the array.

</p><p>
Now consider searching for an element that isn't in the array, say 42:

</p><table>
<tbody><tr>
<th></th>
<th>lo</th>
<th>hi</th>
<th></th>
</tr>
<tr>
<td>Before entering the loop</td>
<td>0</td>
<td>14</td>
<td>mid = 7, examine a[7] = 47</td>
</tr><tr>
<td>After the first iteration</td>
<td>0</td>
<td>6</td>
<td>mid = 3, examine a[3] = 27</td>
</tr><tr>
<td>After the second iteration</td>
<td>4</td>
<td>6</td>
<td>mid = 5, examine a[5] = 36</td>
</tr><tr>
<td>After the third iteration</td>
<td>6</td>
<td>6</td>
<td>mid = 6, examine a[6] = 40</td>
</tr><tr>
<td>After the fourth iteration</td>
<td>7</td>
<td>6</td>
<td>exit the loop</td>
</tr>
</tbody></table>

<p>
Again we examined 4 elements of the array.

</p><div class="units-row">
<div class="unit-60">

<h3>Analysis of binary search</h3>

<p>
The loop here has two control variables, <code>lo</code> and <code>hi</code>.

</p><ul>
<li>The size of the input is the length of the list, n.
</li><li>The fundamental step is examination of an element of the array,
which is the same as an iteration of the loop.
</li><li>On each iteration of the loop, we halve hi-lo+2 (initially n+1)
until it reaches 1:

<table>
<tbody><tr>
<th></th>
<th>lo</th>
<th>hi</th>
<th>hi-lo+2</th>
</tr>
<tr>
<td>Before entering the loop</td>
<td>0</td>
<td>14</td>
<td>16</td>
</tr><tr>
<td>After the first iteration</td>
<td>0</td>
<td>6</td>
<td>8</td>
</tr><tr>
<td>After the second iteration</td>
<td>4</td>
<td>6</td>
<td>4</td>
</tr><tr>
<td>After the third iteration</td>
<td>6</td>
<td>6</td>
<td>2</td>
</tr><tr>
<td>After the fourth iteration</td>
<td>7</td>
<td>6</td>
<td>1</td>
</tr>
</tbody></table>

</li></ul>
<p>
How many times do we have to halve the size?

</p></div>

<div class="unit-40">
<img src="./Exponential and logarithmic time_files/binarysearch.svg">
<p>
Performance of binary search.
Surprising fact:
successful searches take on average only one step less than the worst case.
(Why?)
</p></div>
</div>

<div class="units-row">
<div class="unit-60">

<h3>Reminder: Logarithms</h3>

The logarithm of a number is the exponent to which another fixed value,
the base, must be raised to produce that number.
We shall assume the base is 2.
<ul>
<li>For example, log(32), the logarithm of 32 to base 2 is 5, because 32 = 2<sup>5</sup>
</li><li>More generally, if y = 2<sup>x</sup>, then x = log(y)
</li></ul>
<p>
That is, the logarithm graph is the mirror image of the exponential graph
about the diagonal.
Logarithmic complexity is as good and exponential complexity is bad.
So O(log n) grows much more slowly than O(n).

</p><div class="aside">
Actually this is log<sub>2</sub>(y).
It's possible to have logarithms to other bases,
but it can be shown that they are a constant factor times the logarithm
to base 2, and therefore also O(log n).
</div>

<div class="task">
What are the approximate values of log(1000) and log(1,000,000)?
</div>

</div>

<div class="unit-40">
<img src="./Exponential and logarithmic time_files/logarithmic.svg">
</div>
</div>

<div class="units-row">
<div class="unit-60">

<h3>A variation on binary search</h3>

<p>
We have seen that although the equality test allows the binary search to
terminate early, that yields little gain in practice.
So let's consider a variation omitting that test.
Let <code>mid</code> be an index in the middle of the array:

</p><center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>mid-1</td>
<td>mid</td>
<td>mid+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="cell" colspan="5" style="text-align:center"></td>
<td class="cell"></td>
<td class="cell" colspan="5" style="text-align:center"></td>
</tr>
</tbody></table>
</center>

<p>
Now when we test a[mid] &lt; k, there are only two cases:
</p><ul>

<li>If a[mid] &lt; k, then we search a[mid+1..n-1]:

<center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>mid-1</td>
<td>mid</td>
<td>mid+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="6" style="text-align:center">&lt; k</td>
<td class="cell" colspan="5" style="text-align:center"></td>
</tr>
</tbody></table>
</center>

</li><li>If a[mid] ≥ k, then we search a[0..mid-1]:

<center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>mid-1</td>
<td>mid</td>
<td>mid+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="cell" colspan="5" style="text-align:center"></td>
<td class="sortedcell" colspan="6" style="text-align:center">≥ k</td>
</tr>
</tbody></table>
</center>

</li></ul>

<p>
At we repeat the process, at each stage the array looks like this:

</p><center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>lo-1</td>
<td>lo</td><td>...</td><td>hi</td>
<td>hi+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="5" style="text-align:center">&lt; k</td>
<td class="cell" colspan="3"></td>
<td class="sortedcell" colspan="5" style="text-align:center">≥ k</td>
</tr>
</tbody></table>
</center>

<p>
Eventually <code>lo</code> and <code>hi</code> will cross,
and the loop will terminate with this situation:

</p><center>
<table class="array">
<tbody><tr>
<td></td>
<td>0</td><td></td><td>...</td><td></td><td>hi = lo-1</td>
<td>lo = hi+1</td><td></td><td>...</td><td></td><td>n-1</td>
</tr><tr>
<td>a</td>
<td class="sortedcell" colspan="5" style="text-align:center">&lt; k</td>
<td class="sortedcell" colspan="5" style="text-align:center">≥ k</td>
</tr>
</tbody></table>
</center>

<p>
Then if <code>k</code> is in the array, it will be at position <code>lo</code>.
But compared to the original algorithm,
the final value of <code>lo</code> contains additional information:
</p><ul>
<li>If <code>k</code> is not in the array, then <code>lo</code> is the
position where it would be inserted.
</li><li>If there are several copies of <code>k</code> in the array,
then <code>lo</code> is the position of the first one.
</li></ul>

<p>
Here is the modified algorithm:

</p><div class="pseudocode" id="AltBinarySearch">
<div class="codeheader">AltBinarySearch(a[0..n-1], k)</div>
<pre>lo ← 0
hi ← n-1
</pre>
<span class="invariant"><b>invariant:</b> 0 ≤ lo ≤ hi+1 ≤ n and a[0..lo-1] &lt; k ≤ a[hi+1..n-1]</span>
<pre>WHILE lo ≤ hi
        mid ← (lo+hi) DIV 2
        IF a[mid] &lt; k
                lo ← mid+1
        ELSE
                hi ← mid-1
RETURN lo
</pre>
</div>

<script language="JavaScript">
getProcedure("AltBinarySearch").cellColour = bsearchColour;
</script>

<p>
Its worst case time is the same as the original algorithm, O(log n).
Unlike the original, it always takes that much time.
On the other hand, it only does one comparison each time round the loop,
and it gives more information (as discussed above).

</p></div>
</div>

<div class="task">
Try stepping through the modified binary search:

<canvas id="altbinarySearch" width="950" height="280">
Your browser does not support the HTML5 canvas tag.
</canvas>
Search key:
<input type="text" id="altbinarySearchKey" size="2" value="62" onchange="altbinarySearch.setVar(&#39;k&#39;, Number(this.value))">
<button onclick="altbinarySearch.reset()">Reset</button>
<button onclick="altbinarySearch.step()">Single step</button>
<button onclick="altbinarySearch.bigStep()">Big step</button>
<button onclick="altbinarySearch.run()">Run</button>
<button onclick="altbinarySearch.stop()">Stop</button>

<script language="JavaScript">
var altbinarySearch = new CodeApplet("altbinarySearch", "AltBinarySearch",
	{a:[14,16,22,27,34,36,40,47,51,58,62,63,77,85,93],
	 k:Number(document.getElementById('altbinarySearchKey').value)});
</script>

<p>
To see the difference with the original algorithm, try searching for 47.

</p></div>

<h2>Complexity classes</h2>

<div class="units-row">
<div class="unit-60">
<p>
Now we can do a more complete survey of complexity classes,
in order of increasing rate of growth:
</p><dl>
<dt>O(1) Constant
</dt><dd>The algorithm always takes the
same amount of time, regardless of the size of the input --
very good, but rare.
Occurs with algorithms that examine only a part of the input,
e.g. algorithms that select a single element.

</dd><dt>O(log n) Logarithmic
</dt><dd>The amount of time taken grows logarithmically (good).
This is typical of algorithms that repeatedly cut the size of the problem
by some fraction, e.g. binary search.

</dd><dt>O(n) Linear
</dt><dd>Time taken grows in direct proportion to input size (good/OK).
Typically of algorithms making a limited number of passes over the input,
e.g. sequential search, sum elements, find maximum.
Any algorithm that examines all its input must take at least linear time.

</dd><dt>O(n log n) Log-linear
</dt><dd>e.g. fast sorting algorithms (week 7).

</dd><dt>O(n<sup>2</sup>) Quadratic
</dt><dd>The time taken grows in proportion to the square
of the input size (OK/bad).
This often occurs with algorithms involving two nested loops,
e.g. AllDifferent (week 2), selection sort, insertion sort from last week.

</dd><dt>O(n<sup>3</sup>) Cubic
</dt><dd>The time taken grows in proportion to the cube
of the input size (not so good).
This often occurs with algorithms involving three nested loops,
e.g. naive multiplication of <i>n</i>-by-<i>n</i> matrices.

</dd><dt>O(n<sup>k</sup>) Polynomial (general case of the above)
</dt><dd>This is the limit of what is usually considered "feasible",
though it can be very expensive for larger <i>k</i>.

</dd><dt>O(2<sup>n</sup>) Exponential
</dt><dd>Time taken doubles each time the size increases by 1 (bad).
This is typical of algorithms that examine all possible combinations
from a set (exhaustive search), e.g. truth table, knapsack.

</dd><dt>O(n!) Factorial
</dt><dd>n! = 1*2*3* ... *n (even worse than exponential).
This is typical of algorithms that examine all possible permutations
from a set (exhaustive search), e.g. Hamiltonian path (travelling salesman).

</dd></dl>

<p>
When adding functions of different classes, we know that the lower ones
in this list dominate the earlier ones, so the earlier ones can be ignored.
For example, n log n + n<sup>2</sup> is O(n<sup>2</sup>).

</p></div>

<div class="unit-40">
<img src="./Exponential and logarithmic time_files/good.svg">
<img src="./Exponential and logarithmic time_files/bad.svg">
</div>

</div>

<hr noshade="" size="1">

</div>  <!-- End of soiContent -->
<!--
<div class="modified">Last modified by Seb: 26 Sep 2013</div>
-->
</div> <!-- end of page -->



</body></html>